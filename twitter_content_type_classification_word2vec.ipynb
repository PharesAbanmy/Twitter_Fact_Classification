{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from tqdm import tqdm\n",
    "import light_stemmer_py36\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "from time import time\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47637, 29)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('content_type_full.csv')\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43431, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('content_type.csv')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opinion          35063\n",
       "fact              5542\n",
       "other             3608\n",
       "spam              2440\n",
       "hatful speech      531\n",
       "sarcasm            454\n",
       "Name: content_type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df1.merge(df2, left_on='tweet_link', right_on='tweet_link')\n",
    "df = df.drop(columns=['body_y', 'tweet_id_y']).rename(columns={'body_x':'body', 'tweet_id_x':'tweet_id'})\n",
    "df['content_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47638, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = mysql.connector.connect(\n",
    "  host=\"\",\n",
    "  user=\"data_science\",\n",
    "  password=\"data-$cience\",\n",
    "  database=\"annotation\"\n",
    ")\n",
    "\n",
    "mycursor = connection.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64894, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(112532, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"SELECT tweet_link, body, content_type, `content_type:confidence` FROM results_content_sentiment_topic LIMIT 100000;\"\n",
    "mycursor.execute(query)\n",
    "print(pd.read_sql(query, connection).shape)\n",
    "df = df.append(pd.read_sql(query, connection));\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7576, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120108, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"SELECT tweet_link, body, content_type, `content_type:confidence` FROM results_saudi_content_sentiment_topic WHERE content_type != 'chat' LIMIT 100000;\"\n",
    "mycursor.execute(query)\n",
    "print(pd.read_sql(query, connection).shape)\n",
    "df = df.append(pd.read_sql(query, connection));\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Droping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112752, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=\"tweet_link\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opinion          70548\n",
       "fact             13022\n",
       "other             8224\n",
       "spam              7184\n",
       "hatful speech     1556\n",
       "sarcasm           1248\n",
       "Name: content_type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation, \n",
    "    remove words containing numbers and removing stopwords.'''\n",
    "    # to lowercase\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    # Removing URLs\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    # Removing emojis\n",
    "    text = re.sub(r'&#\\d*','',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Drop NaN from 'tweet_body'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112752, 31)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['body'], how='all', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Stemming 'body'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body'] = df['body'].apply(light_stemmer_py36.stem, args=(True,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Droping unwanted types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opinion    70548\n",
       "fact       13022\n",
       "spam        7184\n",
       "Name: content_type, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing 'hateful speach'\n",
    "df = df[df['content_type'] != 'hatful speech']\n",
    "# Removing 'sarcasm'\n",
    "df = df[df['content_type'] != 'sarcasm']\n",
    "# Removing 'hateful speach'\n",
    "df = df[df['content_type'] != 'other']\n",
    "\n",
    "df['content_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Filtering df with confidence > 0.8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opinion    27094\n",
       "fact        2216\n",
       "spam        1884\n",
       "Name: content_type, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filterd = df[df['content_type:confidence'] > 0.8]\n",
    "df_filterd['content_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Undersampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fact       2216\n",
       "opinion    2200\n",
       "spam       1884\n",
       "Name: content_type, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filterd = df_filterd.sort_values(by='content_type').reset_index()[['tweet_id', 'body', 'content_type']]\n",
    "df_filterd.drop(df_filterd[df_filterd['content_type'] == 'opinion'].index[2200:], inplace=True)\n",
    "df_filterd['content_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6300, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filterd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>body</th>\n",
       "      <th>content_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>عاجل | رهان: ليس قوي حر غيير عتراض علي خطوة لك...</td>\n",
       "      <td>fact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>اطلقت #وزارة_الداخل يوم جمعة درة «تحدي ابشر» ش...</td>\n",
       "      <td>fact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1251255981755031553</td>\n",
       "      <td>هديد صريح قتل من \"مغرد\" جب زميل جمال ريان. وما...</td>\n",
       "      <td>fact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>كلام خطير داخل #البرلمان_التونسي.. ائب ونسي ها...</td>\n",
       "      <td>fact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>@Sami_Alhomood اِنَّاۤ اَنزَلۡنَـٰهُ ِی َیۡلَة...</td>\n",
       "      <td>fact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               body  \\\n",
       "0                  NaN  عاجل | رهان: ليس قوي حر غيير عتراض علي خطوة لك...   \n",
       "1                  NaN  اطلقت #وزارة_الداخل يوم جمعة درة «تحدي ابشر» ش...   \n",
       "2  1251255981755031553  هديد صريح قتل من \"مغرد\" جب زميل جمال ريان. وما...   \n",
       "3                  NaN  كلام خطير داخل #البرلمان_التونسي.. ائب ونسي ها...   \n",
       "4                  NaN  @Sami_Alhomood اِنَّاۤ اَنزَلۡنَـٰهُ ِی َیۡلَة...   \n",
       "\n",
       "  content_type  \n",
       "0         fact  \n",
       "1         fact  \n",
       "2         fact  \n",
       "3         fact  \n",
       "4         fact  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filterd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [nltk.word_tokenize(sent) for sent in df_filterd['body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:38:42: collecting all words and their counts\n",
      "INFO - 11:38:42: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 11:38:42: collected 30079 word types from a corpus of 311521 raw words and 6300 sentences\n",
      "INFO - 11:38:42: Loading a fresh vocabulary\n",
      "INFO - 11:38:42: effective_min_count=20 retains 1531 unique words (5% of original 30079, drops 28548)\n",
      "INFO - 11:38:42: effective_min_count=20 leaves 238786 word corpus (76% of original 311521, drops 72735)\n",
      "INFO - 11:38:42: deleting the raw counts dictionary of 30079 items\n",
      "INFO - 11:38:42: sample=6e-05 downsamples 840 most-common words\n",
      "INFO - 11:38:42: downsampling leaves estimated 65459 word corpus (27.4% of prior 238786)\n",
      "INFO - 11:38:42: estimated required memory for 1531 words and 300 dimensions: 4439900 bytes\n",
      "INFO - 11:38:42: resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.01 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(words, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:38:42: training model with 7 workers on 1531 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
      "INFO - 11:38:42: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:42: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:42: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:42: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:42: EPOCH - 1 : training on 311521 raw words (65313 effective words) took 0.1s, 746776 effective words/s\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:43: EPOCH - 2 : training on 311521 raw words (65400 effective words) took 0.1s, 801400 effective words/s\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:43: EPOCH - 3 : training on 311521 raw words (65599 effective words) took 0.1s, 794196 effective words/s\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:43: EPOCH - 4 : training on 311521 raw words (65382 effective words) took 0.1s, 782929 effective words/s\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:43: EPOCH - 5 : training on 311521 raw words (65462 effective words) took 0.1s, 799802 effective words/s\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:43: EPOCH - 6 : training on 311521 raw words (65388 effective words) took 0.1s, 799291 effective words/s\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:43: EPOCH - 7 : training on 311521 raw words (65409 effective words) took 0.1s, 732919 effective words/s\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:43: EPOCH - 8 : training on 311521 raw words (65330 effective words) took 0.1s, 701581 effective words/s\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:43: EPOCH - 9 : training on 311521 raw words (65640 effective words) took 0.1s, 791061 effective words/s\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:43: EPOCH - 10 : training on 311521 raw words (65470 effective words) took 0.1s, 776076 effective words/s\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:43: EPOCH - 11 : training on 311521 raw words (65199 effective words) took 0.1s, 793552 effective words/s\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:43: EPOCH - 12 : training on 311521 raw words (65360 effective words) took 0.1s, 777076 effective words/s\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:38:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:44: EPOCH - 13 : training on 311521 raw words (65540 effective words) took 0.1s, 766628 effective words/s\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:44: EPOCH - 14 : training on 311521 raw words (65327 effective words) took 0.1s, 757560 effective words/s\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:44: EPOCH - 15 : training on 311521 raw words (65463 effective words) took 0.1s, 827238 effective words/s\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:44: EPOCH - 16 : training on 311521 raw words (65503 effective words) took 0.1s, 776022 effective words/s\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:44: EPOCH - 17 : training on 311521 raw words (65471 effective words) took 0.1s, 805450 effective words/s\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:44: EPOCH - 18 : training on 311521 raw words (65072 effective words) took 0.1s, 813626 effective words/s\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:44: EPOCH - 19 : training on 311521 raw words (65452 effective words) took 0.1s, 785835 effective words/s\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:44: EPOCH - 20 : training on 311521 raw words (65880 effective words) took 0.1s, 776553 effective words/s\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:44: EPOCH - 21 : training on 311521 raw words (65540 effective words) took 0.1s, 777193 effective words/s\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:44: EPOCH - 22 : training on 311521 raw words (65303 effective words) took 0.1s, 771181 effective words/s\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:44: EPOCH - 23 : training on 311521 raw words (65720 effective words) took 0.1s, 769774 effective words/s\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:45: EPOCH - 24 : training on 311521 raw words (65598 effective words) took 0.1s, 799357 effective words/s\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:45: EPOCH - 25 : training on 311521 raw words (65554 effective words) took 0.1s, 803220 effective words/s\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:38:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:45: EPOCH - 26 : training on 311521 raw words (65079 effective words) took 0.1s, 787630 effective words/s\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:45: EPOCH - 27 : training on 311521 raw words (65464 effective words) took 0.1s, 816584 effective words/s\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:45: EPOCH - 28 : training on 311521 raw words (65526 effective words) took 0.1s, 803038 effective words/s\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:45: EPOCH - 29 : training on 311521 raw words (65364 effective words) took 0.1s, 777673 effective words/s\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:38:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:38:45: EPOCH - 30 : training on 311521 raw words (65218 effective words) took 0.1s, 798505 effective words/s\n",
      "INFO - 11:38:45: training on a 9345630 raw words (1963026 effective words) took 2.7s, 733094 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.04 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(words, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 11:38:45: precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('خفيض', 0.9361923933029175),\n",
       " ('خصوم', 0.8997214436531067),\n",
       " ('تجر', 0.8619424104690552),\n",
       " ('ون', 0.8453816175460815),\n",
       " ('كوبون', 0.8403830528259277),\n",
       " ('نون', 0.8333255052566528),\n",
       " ('اقوي', 0.8201906681060791),\n",
       " ('127803', 0.815452516078949),\n",
       " ('128087', 0.8002704977989197),\n",
       " ('127879', 0.7798187136650085)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"عروض\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_vec(words, model, num_features):\n",
    "    \"\"\"\n",
    "    Average the word vectors for a set of words\n",
    "    \"\"\"\n",
    "    feature_vec = np.zeros((num_features,),dtype=\"float32\")  # pre-initialize (for speed)\n",
    "    nwords = 0.\n",
    "    index2word_set = set(model.wv.index2word)  # words known to the model\n",
    "\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vec = np.add(feature_vec,model[word])\n",
    "    \n",
    "    feature_vec = np.divide(feature_vec, nwords)\n",
    "    return feature_vec\n",
    "\n",
    "\n",
    "def get_avg_feature_vecs(reviews, model, num_features):\n",
    "    \"\"\"\n",
    "    Calculate average feature vectors for all reviews\n",
    "    \"\"\"\n",
    "    counter = 0.\n",
    "    review_feature_vecs = np.zeros((len(reviews),num_features), dtype='float32')  # pre-initialize (for speed)\n",
    "    \n",
    "    for review in reviews:\n",
    "        review_feature_vecs[counter] = make_feature_vec(review, model, num_features)\n",
    "        counter = counter + 1.\n",
    "    return review_feature_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "vectors = df_filterd['body'].apply(nltk.word_tokenize).apply(make_feature_vec, model=w2v_model, num_features=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.04510013,  0.00696807,  0.02429755, ...,  0.04861059,\n",
       "          0.02181991,  0.09750631],\n",
       "        [ 0.05910603,  0.0995969 ,  0.16164218, ..., -0.0318923 ,\n",
       "         -0.03813394, -0.04824292],\n",
       "        [-0.00186133, -0.04256683, -0.04633546, ...,  0.07554024,\n",
       "          0.03007343,  0.10521155],\n",
       "        ...,\n",
       "        [-0.06829782, -0.02704829,  0.03433926, ..., -0.296299  ,\n",
       "         -0.09889024, -0.13089025],\n",
       "        [ 0.02122662,  0.04868143,  0.14645995, ..., -0.20831859,\n",
       "         -0.06780344, -0.04168772],\n",
       "        [-0.02098111,  0.2796912 ,  0.26398656, ..., -0.1741605 ,\n",
       "         -0.10549866, -0.09894565]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.matrix(vectors.tolist())\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Estimation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding, LSTM, SimpleRNN\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = df_filterd['body']\n",
    "# define class labels\n",
    "labels = df_filterd['content_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6300"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300\n",
      "[0 0 0 ... 2 2 2]\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "vocab_size = 30000\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(len(encoded_docs))\n",
    "\n",
    "encoded_labels = LabelEncoder().fit_transform(labels)\n",
    "print(encoded_labels)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded_labels = encoded_labels.reshape(len(encoded_labels), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(encoded_labels)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6300, 300)\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 300\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 300, 50)           1500000   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 15000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 45003     \n",
      "=================================================================\n",
      "Total params: 1,545,003\n",
      "Trainable params: 1,545,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, onehot_encoded, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "89/89 [==============================] - 2s 17ms/step - loss: 0.9053 - accuracy: 0.5330 - val_loss: 0.6537 - val_accuracy: 0.7857\n",
      "Epoch 2/3\n",
      "89/89 [==============================] - 1s 17ms/step - loss: 0.4288 - accuracy: 0.8663 - val_loss: 0.3347 - val_accuracy: 0.9079\n",
      "Epoch 3/3\n",
      "89/89 [==============================] - 1s 16ms/step - loss: 0.1754 - accuracy: 0.9603 - val_loss: 0.2320 - val_accuracy: 0.9238\n",
      "20/20 [==============================] - 0s 997us/step - loss: 0.2320 - accuracy: 0.9238\n",
      "Accuracy: 92.380953\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64, verbose=1, validation_data=(X_test, y_test))\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred to one_hot\n",
    "y_pred = (y_pred == y_pred.max(axis=1)[:,None]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       212\n",
      "           1       0.88      0.91      0.90       220\n",
      "           2       0.98      0.94      0.96       198\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       630\n",
      "   macro avg       0.93      0.92      0.93       630\n",
      "weighted avg       0.93      0.92      0.92       630\n",
      " samples avg       0.92      0.92      0.92       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
